import numpy as np
import random


import tsinfer
import msprime

import h5py


def make_errors(v, p):
    """
    For each sample an error occurs with probability p. Errors are generated by
    sampling values from the stationary distribution, that is, if we have an
    allele frequency of f, a 1 is emitted with probability f and a
    0 with probability 1 - f. Thus, there is a possibility that an 'error'
    will in fact result in the same value.
    """
    w = np.copy(v)
    if p > 0:
        m = v.shape[0]
        frequency = np.sum(v) / m
        # Randomly choose samples with probability p
        samples = np.where(np.random.random(m) < p)[0]
        # Generate observations from the stationary distribution.
        errors = (np.random.random(samples.shape[0]) < frequency).astype(int)
        w[samples] = errors
    return w


def generate_samples(ts, error_p):
    """
    Returns samples with a bits flipped with a specified probability.

    Rejects any variants that result in a fixed column.
    """
    S = np.zeros((ts.sample_size, ts.num_mutations), dtype=np.int8)
    for variant in ts.variants():
        done = False
        # Reject any columns that have no 1s or no zeros
        while not done:
            S[:, variant.index] = make_errors(variant.genotypes, error_p)
            s = np.sum(S[:, variant.index])
            done = 0 < s < ts.sample_size
    return S

def make_input_hdf5(filename, samples, positions, recombination_rate, sequence_length):
    """
    Builds a HDF5 file suitable for input into the C interface.
    """
    root = h5py.File(filename, "w")
    root.attrs["format_name"] = b"tsinfer"
    root.attrs["format_version"] = (0, 1)
    root.attrs["sequence_length"] = sequence_length

    num_samples, num_sites = samples.shape
    sites_group = root.create_group("sites")
    sites_group.create_dataset("position", (num_sites, ), data=positions, dtype=float)
    sites_group.create_dataset("recombination_rate", (num_sites, ),
            data=recombination_rate, dtype=float)

    samples_group = root.create_group("samples")
    samples_group.create_dataset(
        "haplotypes", (num_samples, num_sites), data=samples, dtype=np.int8)
    root.close()

def tsinfer_dev(
        n, L, seed, num_threads=1, recombination_rate=1e-8,
        error_rate=0, method="C", log_level="WARNING",
        progress=False):

    np.random.seed(seed)
    random.seed(seed)
    L_megabases = int(L * 10**6)

    ts = msprime.simulate(
            n, Ne=10**4, length=L_megabases,
            recombination_rate=1e-8, mutation_rate=1e-8,
            random_seed=seed)
    print("num_sites = ", ts.num_sites)
    if ts.num_sites == 0:
        print("zero sites; skipping")
        return
    positions = np.array([site.position for site in ts.sites()])
    S = generate_samples(ts, error_rate)
    # print(S)

    recombination_rate = np.zeros_like(positions) + recombination_rate

    # hdf5 = make_input_hdf5("tmp.hdf5", S, positions, recombination_rate, L_megabases)
    # print(S)

    tsp = tsinfer.infer(
        S, positions, L_megabases, recombination_rate, error_rate,
        num_threads=num_threads, method=method, log_level=log_level, progress=progress)
    # print(tsp.tables)
    # for t in tsp.trees():
    #     print("tree", t.index)
    #     print(t.draw(format="unicode"))

    Sp = np.zeros((tsp.sample_size, tsp.num_sites), dtype="i1")
    for variant in tsp.variants():
        Sp[:, variant.index] = variant.genotypes
    assert np.all(Sp == S)


def analyse_file(filename):
    ts = msprime.load(filename)

    num_children = np.zeros(ts.num_edgesets, dtype=np.int)
    for j, e in enumerate(ts.edgesets()):
        # print(e.left, e.right, e.parent, ts.time(e.parent), e.children, sep="\t")
        num_children[j] = len(e.children)

    print("total edgesets = ", ts.num_edgesets)
    print("non binary     = ", np.sum(num_children > 2))
    print("max children   = ", np.max(num_children))
    print("mean children  = ", np.mean(num_children))

    # for l, r_out, r_in in ts.diffs():
    #     print(l, len(r_out), len(r_in), sep="\t")

    # for t in ts.trees():
    #     t.draw(
    #         "tree_{}.svg".format(t.index), 4000, 4000, show_internal_node_labels=False,
    #         show_leaf_node_labels=False)
    #     if t.index == 10:
    #         break


def analyse_tracebacks(epoch):
    filename = "tmp__NOBACKUP__/tracebacks/tracebacks{}.pkl".format(epoch)
    import pickle
    with open(filename, "rb") as f:
        tracebacks = pickle.load(f)
    max_len = 0
    for j, L in enumerate(tracebacks):
        if len(L) > max_len:
            max_len = len(L)
            max_index = j
    # print(j, "\t", L)
    print("max len = ", max_len)
    for k, v in tracebacks[max_index].items():
        print(k, "\t", v)



if __name__ == "__main__":

    np.set_printoptions(linewidth=20000)
    np.set_printoptions(threshold=20000000)

    tsinfer_dev(6, 0.1, seed=1, error_rate=0.1, method="P")
    # tsinfer_dev(60, 1000, num_threads=5, seed=1, error_rate=0.1, method="C",
    #         log_level="INFO", progress=True)
    # for seed in range(1, 1000):
    #     print(seed)
    #     tsinfer_dev(36, 10, seed=seed, error_rate=0.1, method="python")
