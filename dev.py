import numpy as np
import random
import os
import h5py
import zarr
import sys
import pandas as pd


import tsinfer
import msprime



def make_errors(v, p):
    """
    For each sample an error occurs with probability p. Errors are generated by
    sampling values from the stationary distribution, that is, if we have an
    allele frequency of f, a 1 is emitted with probability f and a
    0 with probability 1 - f. Thus, there is a possibility that an 'error'
    will in fact result in the same value.
    """
    w = np.copy(v)
    if p > 0:
        m = v.shape[0]
        frequency = np.sum(v) / m
        # Randomly choose samples with probability p
        samples = np.where(np.random.random(m) < p)[0]
        # Generate observations from the stationary distribution.
        errors = (np.random.random(samples.shape[0]) < frequency).astype(int)
        w[samples] = errors
    return w


def generate_samples(ts, error_p):
    """
    Returns samples with a bits flipped with a specified probability.

    Rejects any variants that result in a fixed column.
    """
    S = np.zeros((ts.sample_size, ts.num_mutations), dtype=np.int8)
    for variant in ts.variants():
        done = False
        # Reject any columns that have no 1s or no zeros
        while not done:
            S[:, variant.index] = make_errors(variant.genotypes, error_p)
            s = np.sum(S[:, variant.index])
            done = 0 < s < ts.sample_size
    return S

def tsinfer_dev(
        n, L, seed, num_threads=1, recombination_rate=1e-8,
        error_rate=0, method="C", log_level="WARNING",
        debug=True, progress=False):

    np.random.seed(seed)
    random.seed(seed)
    L_megabases = int(L * 10**6)

    ts = msprime.simulate(
            n, Ne=10**4, length=L_megabases,
            recombination_rate=1e-8, mutation_rate=1e-8,
            random_seed=seed)
    if debug:
        print("num_sites = ", ts.num_sites)
    assert ts.num_sites > 0
    positions = np.array([site.position for site in ts.sites()])
    V = ts.genotype_matrix()
    # S = generate_samples(ts, error_rate)
    # print(S)
    recombination_rate = np.zeros_like(positions) + recombination_rate

    input_root = zarr.group()
    tsinfer.InputFile.build(
        input_root, genotypes=V, position=positions,
        recombination_rate=recombination_rate, sequence_length=ts.sequence_length,
        compress=False)
    ancestors_root = zarr.group()

    tsinfer.build_ancestors(
        input_root, ancestors_root, method=method, chunk_size=16, compress=False)

    ts = tsinfer.match_ancestors(
        input_root, ancestors_root, method=method, num_threads=num_threads)
    assert ts.sequence_length == L_megabases

    # print(ts)
    # print(ts.tables)
    # for t in ts.trees():
    #     print("INTERVAL", t.interval)
    #     print(t.draw(format="unicode"))
    # for interval, e_out, e_in in ts.edge_diffs():
    #     print(interval, e_out)
    A = ancestors_root["ancestors/haplotypes"][:]
    A[A == -1] = 0
    for v in ts.variants():
        # print(v.index)
        # print(A[:,v.index])
        # print(v.genotypes)
        # print()
        assert np.array_equal(v.genotypes, A[:, v.index])
    print("Verified haplotypes")
    # input_hdf5.close()
    # ancestors_hdf5.close()

    # tsp = tsinfer.infer(
    #     S, positions, L_megabases, recombination_rate, error_rate,
    #     num_threads=num_threads, method=method, log_level=log_level, progress=progress)
    # print(tsp.tables)
    # for t in tsp.trees():
    #     print("tree", t.index)
    #     print(t.draw(format="unicode"))

#     Sp = np.zeros((tsp.sample_size, tsp.num_sites), dtype="i1")
#     for variant in tsp.variants():
#         Sp[:, variant.index] = variant.genotypes
#     assert np.all(Sp == S)
#     return tsp


def analyse_file(filename):
    ts = msprime.load(filename)

    num_children = np.zeros(ts.num_edgesets, dtype=np.int)
    for j, e in enumerate(ts.edgesets()):
        # print(e.left, e.right, e.parent, ts.time(e.parent), e.children, sep="\t")
        num_children[j] = len(e.children)

    print("total edgesets = ", ts.num_edgesets)
    print("non binary     = ", np.sum(num_children > 2))
    print("max children   = ", np.max(num_children))
    print("mean children  = ", np.mean(num_children))

    # for l, r_out, r_in in ts.diffs():
    #     print(l, len(r_out), len(r_in), sep="\t")

    # for t in ts.trees():
    #     t.draw(
    #         "tree_{}.svg".format(t.index), 4000, 4000, show_internal_node_labels=False,
    #         show_leaf_node_labels=False)
    #     if t.index == 10:
    #         break

def build_profile_inputs(n, num_megabases):
    L = num_megabases * 10**6
    ts = msprime.simulate(
        n, length=L, Ne=10**4, recombination_rate=1e-8, mutation_rate=1e-8,
        random_seed=10)
    print("Ran simulation: n = ", n, " num_sites = ", ts.num_sites,
            "num_trees =", ts.num_trees)
    input_file = "tmp__NOBACKUP__/large-input-source-n={}-m={}.hdf5".format(
            n, num_megabases)
    ts.dump(input_file)
    V = ts.genotype_matrix()
    # V = np.zeros((ts.num_sites, ts.sample_size), dtype=np.uint8)
    # for v in ts.variants():
    #     V[v.index:] = v.genotypes
    print("Built variant matrix: {:.2f} MiB".format(V.nbytes / (1024 * 1024)))
    positions = np.array([site.position for site in ts.sites()])
    recombination_rate = np.zeros(ts.num_sites) + 1e-8
    input_file = "tmp__NOBACKUP__/profile-n={}_m={}.zarr.tsinf".format(n, num_megabases)
    # with h5py.File(input_file, "w") as input_hdf5:
    # with zarr.ZipStore(input_file) as input_hdf5:
    # input_hdf5 = zarr.DirectoryStore(input_file)
    if os.path.exists(input_file):
        os.unlink(input_file)
    input_hdf5 = zarr.ZipStore(input_file)
    root = zarr.group(store=input_hdf5, overwrite=True)
    tsinfer.InputFile.build(
        root, genotypes=V, position=positions,
        recombination_rate=recombination_rate, sequence_length=ts.sequence_length,
        compression="gzip")
    # input_hdf5.close()
    print("Wrote", input_file)


def large_profile(input_file, output_file, num_threads=2, log_level="DEBUG"):
    hdf5 = h5py.File(input_file, "r")
    tsp = tsinfer.infer(
        samples=hdf5["samples/haplotypes"][:],
        positions=hdf5["sites/position"][:],
        recombination_rate=hdf5["sites/recombination_rate"][:],
        sequence_length=hdf5.attrs["sequence_length"],
        num_threads=num_threads, log_level=log_level, progress=True)
    tsp.dump(output_file)

    # print(tsp.tables)
    # for t in tsp.trees():
    #     print("tree", t.index)
    #     print(t.draw(format="unicode"))

def save_ancestor_ts(
        n, L, seed, num_threads=1, recombination_rate=1e-8,
        resolve_shared_recombinations=False,
        progress=False, error_rate=0, method="C", log_level="WARNING"):
    L_megabases = int(L * 10**6)
    ts = msprime.simulate(
            n, Ne=10**4, length=L_megabases,
            recombination_rate=1e-8, mutation_rate=1e-8,
            random_seed=seed)
    print("num_sites = ", ts.num_sites)
    positions = np.array([site.position for site in ts.sites()])
    S = generate_samples(ts, 0)
    recombination_rate = np.zeros_like(positions) + recombination_rate

    # make_input_hdf5("ancestor_example.hdf5", S, positions, recombination_rate,
    #         ts.sequence_length)

    manager = tsinfer.InferenceManager(
        S, positions, ts.sequence_length, recombination_rate,
        num_threads=num_threads, method=method, progress=progress, log_level=log_level,
        resolve_shared_recombinations=resolve_shared_recombinations)
        # ancestor_traceback_file_pattern="tmp__NOBACKUP__/tracebacks/tb_{}.pkl")

    manager.initialise()
    manager.process_ancestors()
    ts_new = manager.get_tree_sequence()

    A = manager.ancestors()
    # Need to reset the unknown values to be zeros.
    A[A == -1] = 0
    B = np.zeros((manager.num_ancestors, manager.num_sites), dtype=np.int8)
    for v in ts_new.variants():
        B[:, v.index] = v.genotypes
    assert np.array_equal(A, B)
    print(ts_new.tables)
    # ts.dump("tmp__NOBACKUP__/ancestor_ts-{}.hdf5".format(ts.num_sites))
    for t in ts_new.trees():
        print(t.interval)
        print(t.draw(format="unicode"))
    new_nodes = [j for j, node in enumerate(ts_new.nodes()) if node.flags == 0]
    print(new_nodes)
    for e in ts_new.edges():
        if e.child in new_nodes or e.parent in new_nodes:
            print("{:.0f}\t{:.0f}".format(e.left, e.right), e.parent, e.child, sep="\t")

    nodes = ts_new.tables.nodes
    nodes.set_columns(flags=np.ones_like(nodes.flags), time=nodes.time)
    print(nodes)
    t = ts_new.tables
    tsp = msprime.load_tables(
            nodes=nodes, edges=t.edges,  sites=t.sites, mutations=t.mutations)
    print(tsp.tables)
    for j, h in enumerate(tsp.haplotypes()):
        print(j, "\t",h)



def examine_ancestor_ts(filename):
    ts = msprime.load(filename)
    print("num_sites = ", ts.num_sites)
    print("num_trees = ", ts.num_trees)
    print("num_edges = ", ts.num_edges)

    for (left, right), edges_in, edges_out in ts.edge_diffs():
        print("NEW TREE: {:.2f}".format(right - left), len(edges_in), len(edges_out), sep="\t")
        print("OUT")
        for e in edges_out:
            print("\t", e.parent, e.child)
        print("IN")
        for e in edges_in:
            print("\t", e.parent, e.child)

    # zero_edges = 0
    # edges = msprime.EdgeTable()
    # for e in ts.edges():
    #     if e.parent == 0:
    #         zero_edges += 1
    #     else:
    #         edges.add_row(e.left, e.right, e.parent, e.child)
    # print("zero_edges = ", zero_edges, zero_edges / ts.num_edges)
    # t = ts.tables
    # t.edges = edges
    # ts = msprime.load_tables(**t.asdict())
    # print("num_sites = ", ts.num_sites)
    # print("num_trees = ", ts.num_trees)
    # print("num_edges = ", ts.num_edges)

    # for t in ts.trees():
    #     print("Tree:", t.interval)
    #     print(t.draw(format="unicode"))
    #     print("=" * 200)

    # import pickle
    # j = 960
    # filename = "tmp__NOBACKUP__/tracebacks/tb_{}.pkl".format(j)
    # with open(filename, "rb") as f:
    #     debug = pickle.load(f)

    # tracebacks = debug["traceback"]
    # # print("focal = ", debug["focal_sites"])
    # del debug["traceback"]
    # print("debug:", debug)
    # a = debug["ancestor"]
    # lengths = [len(t) for t in tracebacks]
    # import matplotlib as mp
    # # Force matplotlib to not use any Xwindows backend.
    # mp.use('Agg')
    # import matplotlib.pyplot as plt

    # plt.clf()
    # plt.plot(lengths)
    # plt.savefig("tracebacks_{}.png".format(j))

#     start = 0
#     for j, t in enumerate(tracebacks[start:]):
#         print("TB", j, len(t))
#         for k, v in t.items():
#             print("\t", k, "\t", v)

#     site_id = 0
#     for t in ts.trees():
#         for site in t.sites():
#             L = tracebacks[site_id]
#             site_id += 1
#         # print("TREE")
#             print(L)
#             # for x1 in L.values():
#             #     for x2 in L.values():
#             #         print("\t", x1, x2, x1 == x2, sep="\t")
#             print("SITE = ", site_id)
#             print("root children = ", len(t.children(t.root)))
#             for u, v in L.items():
#                 path = []
#                 while u != msprime.NULL_NODE:
#                     path.append(u)
#                     u = t.parent(u)
#                     # if u in L and L[u] == v:
#                     #     print("ERROR", u)
#                 print(v, path)
#             print()
#             node_labels = {u: "{}:{:.2G}".format(u, L[u]) for u in L.keys()}
#             if site_id == 694:
#                 print(t.draw(format="unicode", node_label_text=node_labels))


    # for j, L in enumerate(tracebacks):
    #     print(j, L)
        # if len(L) > max_len:
        #     max_len = len(L)
        #     max_index = j
    # # print(j, "\t", L)
    # print("max len = ", max_len)
    # for k, v in tracebacks[max_index].items():
        # print(k, "\t", v)

def verify(file1, file2):
    ts1 = msprime.load(file1)
    ts2 = msprime.load(file2)
    assert ts1.num_samples == ts2.num_samples
    assert ts1.num_sites == ts2.num_sites

    for v1, v2 in zip(ts1.variants(), ts2.variants()):
        assert v1.position == v2.position
        assert np.array_equal(v1.genotypes, v2.genotypes)


if __name__ == "__main__":

    np.set_printoptions(linewidth=20000)
    np.set_printoptions(threshold=20000000)

    # verify(sys.argv[1], sys.argv[2])

    # build_profile_inputs(10, 1)

    # build_profile_inputs(1000, 100)
    # build_profile_inputs(10**4, 100)
    # build_profile_inputs(10**5, 100)
    # build_profile_inputs(100)

    # large_profile(sys.argv[1], "{}.inferred.hdf5".format(sys.argv[1]),
    #         num_threads=40, log_level="DEBUG")

    # save_ancestor_ts(100, 10, 1, recombination_rate=1, num_threads=2)
    # examine_ancestor_ts(sys.argv[1])

    # save_ancestor_ts(15, 0.03, 7, recombination_rate=1, method="P",
    #         resolve_shared_recombinations=False)

    # tsinfer_dev(11, 0.1, seed=7, num_threads=1, error_rate=0.0, method="C")

    # tsinfer_dev(4, 0.2, seed=84, num_threads=0, error_rate=0.0, method="P")

    for seed in range(1, 10000):
        print(seed)
        # tsinfer_dev(20, 0.2, seed=seed, num_threads=0, error_rate=0.0, method="P")
        tsinfer_dev(30, 2.5, seed=seed, num_threads=0, error_rate=0.0, method="C")

    # tsinfer_dev(60, 1000, num_threads=5, seed=1, error_rate=0.1, method="C",
    #         log_level="INFO", progress=True)
    # for seed in range(1, 1000):
    #     print(seed)
    #     tsinfer_dev(36, 10, seed=seed, error_rate=0.1, method="python")
